#!/usr/bin/env python3
"""
Vulnerability Assessor - Dependency Vulnerability Analysis Tool

Analyzes project dependencies for known vulnerabilities:
- CVE database cross-referencing
- Dependency vulnerability scanning (npm, pip, go.mod, Cargo.toml)
- CVSS risk scoring and prioritization
- Remediation guidance with upgrade paths

Part of the senior-secops skill package.
"""

import argparse
import csv
import json
import os
import re
import sys
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from io import StringIO
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple


class Severity(Enum):
    """Vulnerability severity based on CVSS scores"""
    CRITICAL = 4  # CVSS 9.0-10.0
    HIGH = 3      # CVSS 7.0-8.9
    MEDIUM = 2    # CVSS 4.0-6.9
    LOW = 1       # CVSS 0.1-3.9
    UNKNOWN = 0   # No CVSS available


@dataclass
class Dependency:
    """A project dependency"""
    name: str
    version: str
    ecosystem: str  # npm, pypi, go, cargo, maven
    file_path: str
    is_dev: bool = False


@dataclass
class Vulnerability:
    """A known vulnerability in a dependency"""
    cve_id: str
    package: str
    affected_versions: str
    fixed_version: Optional[str]
    severity: Severity
    cvss_score: float
    description: str
    recommendation: str
    references: List[str] = field(default_factory=list)


@dataclass
class VulnerabilityFinding:
    """A vulnerability finding in the project"""
    dependency: Dependency
    vulnerability: Vulnerability
    file_path: str
    exploitability: str
    business_impact: str


class VulnerabilityAssessor:
    """Dependency vulnerability assessment tool"""

    # Known vulnerable package patterns (simplified CVE database simulation)
    # In production, this would query NVD, OSV, or similar databases
    KNOWN_VULNERABILITIES: Dict[str, List[Dict]] = {
        # npm packages
        'lodash': [
            {'cve': 'CVE-2021-23337', 'affected': '<4.17.21', 'fixed': '4.17.21',
             'severity': Severity.HIGH, 'cvss': 7.5,
             'description': 'Command Injection in lodash',
             'recommendation': 'Upgrade lodash to version 4.17.21 or later'}
        ],
        'express': [
            {'cve': 'CVE-2024-29041', 'affected': '<4.19.2', 'fixed': '4.19.2',
             'severity': Severity.MEDIUM, 'cvss': 6.1,
             'description': 'Open redirect vulnerability in Express',
             'recommendation': 'Upgrade express to version 4.19.2 or later'}
        ],
        'axios': [
            {'cve': 'CVE-2023-45857', 'affected': '<1.6.0', 'fixed': '1.6.0',
             'severity': Severity.HIGH, 'cvss': 7.5,
             'description': 'CSRF vulnerability in axios',
             'recommendation': 'Upgrade axios to version 1.6.0 or later'}
        ],
        'jsonwebtoken': [
            {'cve': 'CVE-2022-23529', 'affected': '<9.0.0', 'fixed': '9.0.0',
             'severity': Severity.CRITICAL, 'cvss': 9.8,
             'description': 'JWT signature bypass vulnerability',
             'recommendation': 'Upgrade jsonwebtoken to version 9.0.0 or later'}
        ],
        'minimatch': [
            {'cve': 'CVE-2022-3517', 'affected': '<3.0.5', 'fixed': '3.0.5',
             'severity': Severity.HIGH, 'cvss': 7.5,
             'description': 'ReDoS vulnerability in minimatch',
             'recommendation': 'Upgrade minimatch to version 3.0.5 or later'}
        ],
        # Python packages
        'django': [
            {'cve': 'CVE-2024-24680', 'affected': '<4.2.10', 'fixed': '4.2.10',
             'severity': Severity.HIGH, 'cvss': 7.5,
             'description': 'Denial of Service via intcomma filter',
             'recommendation': 'Upgrade Django to version 4.2.10 or later'}
        ],
        'flask': [
            {'cve': 'CVE-2023-30861', 'affected': '<2.3.2', 'fixed': '2.3.2',
             'severity': Severity.MEDIUM, 'cvss': 5.3,
             'description': 'Possible disclosure of session cookie',
             'recommendation': 'Upgrade Flask to version 2.3.2 or later'}
        ],
        'requests': [
            {'cve': 'CVE-2023-32681', 'affected': '<2.31.0', 'fixed': '2.31.0',
             'severity': Severity.MEDIUM, 'cvss': 6.1,
             'description': 'Unintended leak of Proxy-Authorization header',
             'recommendation': 'Upgrade requests to version 2.31.0 or later'}
        ],
        'pillow': [
            {'cve': 'CVE-2023-44271', 'affected': '<10.0.1', 'fixed': '10.0.1',
             'severity': Severity.HIGH, 'cvss': 7.5,
             'description': 'Denial of Service via image processing',
             'recommendation': 'Upgrade Pillow to version 10.0.1 or later'}
        ],
        'pyyaml': [
            {'cve': 'CVE-2020-14343', 'affected': '<5.4', 'fixed': '5.4',
             'severity': Severity.CRITICAL, 'cvss': 9.8,
             'description': 'Arbitrary code execution via yaml.load',
             'recommendation': 'Upgrade PyYAML to 5.4+ and use yaml.safe_load()'}
        ],
        'cryptography': [
            {'cve': 'CVE-2023-49083', 'affected': '<41.0.6', 'fixed': '41.0.6',
             'severity': Severity.HIGH, 'cvss': 7.5,
             'description': 'NULL pointer dereference in cryptography',
             'recommendation': 'Upgrade cryptography to version 41.0.6 or later'}
        ],
        # Go packages
        'golang.org/x/net': [
            {'cve': 'CVE-2023-44487', 'affected': '<0.17.0', 'fixed': '0.17.0',
             'severity': Severity.CRITICAL, 'cvss': 9.8,
             'description': 'HTTP/2 rapid reset attack vulnerability',
             'recommendation': 'Upgrade golang.org/x/net to 0.17.0 or later'}
        ],
        'golang.org/x/crypto': [
            {'cve': 'CVE-2022-27191', 'affected': '<0.0.0-20220315160706', 'fixed': '0.0.0-20220315160706',
             'severity': Severity.HIGH, 'cvss': 7.5,
             'description': 'Panic in SSH server on malformed input',
             'recommendation': 'Upgrade golang.org/x/crypto to latest version'}
        ],
    }

    def __init__(self, target_path: str, config: Optional[Dict] = None,
                 verbose: bool = False):
        self.target_path = Path(target_path)
        self.config = config or {}
        self.verbose = verbose
        self.dependencies: List[Dependency] = []
        self.findings: List[VulnerabilityFinding] = []
        self.manifest_files_found = 0

    def run(self) -> Dict:
        """Execute vulnerability assessment"""
        if self.verbose:
            print(f"Starting vulnerability assessment: {self.target_path}")

        if not self.target_path.exists():
            raise ValueError(f"Target path does not exist: {self.target_path}")

        # Discover dependencies
        self._discover_dependencies()

        # Assess vulnerabilities
        self._assess_vulnerabilities()

        return self._generate_results()

    def _discover_dependencies(self):
        """Discover all project dependencies"""
        if self.target_path.is_file():
            self._parse_manifest_file(self.target_path)
        else:
            for root, dirs, files in os.walk(self.target_path):
                # Skip common non-project directories
                dirs[:] = [d for d in dirs if d not in {
                    'node_modules', '__pycache__', '.git', 'venv', 'env',
                    '.venv', 'dist', 'build', 'vendor', '.idea', '.vscode'
                }]

                for file_name in files:
                    file_path = Path(root) / file_name
                    self._parse_manifest_file(file_path)

    def _parse_manifest_file(self, file_path: Path):
        """Parse dependency manifest file"""
        try:
            if file_path.name == 'package.json':
                self._parse_package_json(file_path)
            elif file_path.name == 'package-lock.json':
                self._parse_package_lock_json(file_path)
            elif file_path.name == 'requirements.txt':
                self._parse_requirements_txt(file_path)
            elif file_path.name == 'Pipfile.lock':
                self._parse_pipfile_lock(file_path)
            elif file_path.name == 'pyproject.toml':
                self._parse_pyproject_toml(file_path)
            elif file_path.name == 'go.mod':
                self._parse_go_mod(file_path)
            elif file_path.name == 'Cargo.toml':
                self._parse_cargo_toml(file_path)
            elif file_path.name == 'pom.xml':
                self._parse_pom_xml(file_path)
            elif file_path.name == 'Gemfile.lock':
                self._parse_gemfile_lock(file_path)
        except Exception as e:
            if self.verbose:
                print(f"  Error parsing {file_path}: {e}")

    def _parse_package_json(self, file_path: Path):
        """Parse npm package.json"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        self.manifest_files_found += 1

        for name, version in data.get('dependencies', {}).items():
            self.dependencies.append(Dependency(
                name=name,
                version=self._clean_version(version),
                ecosystem='npm',
                file_path=str(file_path),
                is_dev=False
            ))

        for name, version in data.get('devDependencies', {}).items():
            self.dependencies.append(Dependency(
                name=name,
                version=self._clean_version(version),
                ecosystem='npm',
                file_path=str(file_path),
                is_dev=True
            ))

    def _parse_package_lock_json(self, file_path: Path):
        """Parse npm package-lock.json for exact versions"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        self.manifest_files_found += 1

        packages = data.get('packages', {})
        for pkg_path, pkg_data in packages.items():
            if pkg_path and 'node_modules/' in pkg_path:
                name = pkg_path.split('node_modules/')[-1]
                version = pkg_data.get('version', '')
                if name and version:
                    self.dependencies.append(Dependency(
                        name=name,
                        version=version,
                        ecosystem='npm',
                        file_path=str(file_path),
                        is_dev=pkg_data.get('dev', False)
                    ))

    def _parse_requirements_txt(self, file_path: Path):
        """Parse Python requirements.txt"""
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        self.manifest_files_found += 1

        for line in lines:
            line = line.strip()
            if not line or line.startswith('#') or line.startswith('-'):
                continue

            # Parse package==version or package>=version patterns
            match = re.match(r'^([a-zA-Z0-9_\-\.]+)\s*([<>=!~]+)\s*([0-9][0-9a-zA-Z\.\-]*)', line)
            if match:
                self.dependencies.append(Dependency(
                    name=match.group(1).lower(),
                    version=match.group(3),
                    ecosystem='pypi',
                    file_path=str(file_path),
                    is_dev=False
                ))

    def _parse_pipfile_lock(self, file_path: Path):
        """Parse Python Pipfile.lock"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        self.manifest_files_found += 1

        for name, info in data.get('default', {}).items():
            version = info.get('version', '').lstrip('=')
            self.dependencies.append(Dependency(
                name=name.lower(),
                version=version,
                ecosystem='pypi',
                file_path=str(file_path),
                is_dev=False
            ))

        for name, info in data.get('develop', {}).items():
            version = info.get('version', '').lstrip('=')
            self.dependencies.append(Dependency(
                name=name.lower(),
                version=version,
                ecosystem='pypi',
                file_path=str(file_path),
                is_dev=True
            ))

    def _parse_pyproject_toml(self, file_path: Path):
        """Parse Python pyproject.toml (simplified)"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        self.manifest_files_found += 1

        # Simple regex-based parsing (would use tomli in production)
        deps_match = re.search(r'\[project\].*?dependencies\s*=\s*\[(.*?)\]', content, re.DOTALL)
        if deps_match:
            deps_text = deps_match.group(1)
            for line in deps_text.split(','):
                line = line.strip().strip('"\'')
                match = re.match(r'([a-zA-Z0-9_\-\.]+)\s*([<>=!~]+)\s*([0-9][0-9a-zA-Z\.\-]*)', line)
                if match:
                    self.dependencies.append(Dependency(
                        name=match.group(1).lower(),
                        version=match.group(3),
                        ecosystem='pypi',
                        file_path=str(file_path),
                        is_dev=False
                    ))

    def _parse_go_mod(self, file_path: Path):
        """Parse Go go.mod"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        self.manifest_files_found += 1

        # Parse require block
        require_match = re.search(r'require\s*\((.*?)\)', content, re.DOTALL)
        if require_match:
            for line in require_match.group(1).split('\n'):
                match = re.match(r'\s*([^\s]+)\s+v?([0-9][^\s]*)', line)
                if match:
                    self.dependencies.append(Dependency(
                        name=match.group(1),
                        version=match.group(2),
                        ecosystem='go',
                        file_path=str(file_path),
                        is_dev=False
                    ))

        # Parse single require statements
        for match in re.finditer(r'^require\s+([^\s]+)\s+v?([0-9][^\s]*)', content, re.MULTILINE):
            self.dependencies.append(Dependency(
                name=match.group(1),
                version=match.group(2),
                ecosystem='go',
                file_path=str(file_path),
                is_dev=False
            ))

    def _parse_cargo_toml(self, file_path: Path):
        """Parse Rust Cargo.toml (simplified)"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        self.manifest_files_found += 1

        # Parse [dependencies] section
        in_deps = False
        for line in content.split('\n'):
            if re.match(r'\[dependencies\]', line):
                in_deps = True
                continue
            elif re.match(r'\[', line):
                in_deps = False
                continue

            if in_deps:
                match = re.match(r'([a-zA-Z0-9_\-]+)\s*=\s*["\']([0-9][^"\']*)["\']', line)
                if match:
                    self.dependencies.append(Dependency(
                        name=match.group(1),
                        version=match.group(2),
                        ecosystem='cargo',
                        file_path=str(file_path),
                        is_dev=False
                    ))

    def _parse_pom_xml(self, file_path: Path):
        """Parse Maven pom.xml (simplified)"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        self.manifest_files_found += 1

        # Simple regex-based parsing
        for match in re.finditer(
            r'<dependency>.*?<groupId>([^<]+)</groupId>.*?<artifactId>([^<]+)</artifactId>.*?<version>([^<]+)</version>.*?</dependency>',
            content, re.DOTALL
        ):
            self.dependencies.append(Dependency(
                name=f"{match.group(1)}:{match.group(2)}",
                version=match.group(3),
                ecosystem='maven',
                file_path=str(file_path),
                is_dev=False
            ))

    def _parse_gemfile_lock(self, file_path: Path):
        """Parse Ruby Gemfile.lock"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        self.manifest_files_found += 1

        in_specs = False
        for line in content.split('\n'):
            if line.strip() == 'specs:':
                in_specs = True
                continue
            elif line and not line.startswith(' '):
                in_specs = False
                continue

            if in_specs:
                match = re.match(r'\s{4}([a-zA-Z0-9_\-]+)\s+\(([0-9][^\)]*)\)', line)
                if match:
                    self.dependencies.append(Dependency(
                        name=match.group(1),
                        version=match.group(2),
                        ecosystem='rubygems',
                        file_path=str(file_path),
                        is_dev=False
                    ))

    def _clean_version(self, version: str) -> str:
        """Clean version string"""
        # Remove common prefixes like ^, ~, >=, etc.
        return re.sub(r'^[\^~>=<]+', '', version).strip()

    def _assess_vulnerabilities(self):
        """Assess vulnerabilities in discovered dependencies"""
        for dep in self.dependencies:
            vulns = self._check_vulnerabilities(dep)
            for vuln in vulns:
                finding = VulnerabilityFinding(
                    dependency=dep,
                    vulnerability=vuln,
                    file_path=dep.file_path,
                    exploitability=self._assess_exploitability(vuln),
                    business_impact=self._assess_business_impact(vuln, dep)
                )
                self.findings.append(finding)

    def _check_vulnerabilities(self, dep: Dependency) -> List[Vulnerability]:
        """Check if dependency has known vulnerabilities"""
        vulnerabilities = []
        pkg_name = dep.name.lower()

        # Check our known vulnerabilities database
        known_vulns = self.KNOWN_VULNERABILITIES.get(pkg_name, [])

        for vuln_data in known_vulns:
            if self._is_version_affected(dep.version, vuln_data['affected']):
                vuln = Vulnerability(
                    cve_id=vuln_data['cve'],
                    package=dep.name,
                    affected_versions=vuln_data['affected'],
                    fixed_version=vuln_data.get('fixed'),
                    severity=vuln_data['severity'],
                    cvss_score=vuln_data['cvss'],
                    description=vuln_data['description'],
                    recommendation=vuln_data['recommendation'],
                    references=[f"https://nvd.nist.gov/vuln/detail/{vuln_data['cve']}"]
                )
                vulnerabilities.append(vuln)

        return vulnerabilities

    def _is_version_affected(self, current_version: str, affected_range: str) -> bool:
        """Check if current version is in affected range (simplified)"""
        # Parse the affected range (e.g., "<4.17.21")
        match = re.match(r'<([0-9][0-9a-zA-Z\.\-]*)', affected_range)
        if match:
            threshold = match.group(1)
            return self._compare_versions(current_version, threshold) < 0
        return False

    def _compare_versions(self, v1: str, v2: str) -> int:
        """Compare two version strings (simplified)"""
        def normalize(v):
            return [int(x) if x.isdigit() else 0 for x in re.split(r'[.\-]', v)][:4]

        n1, n2 = normalize(v1), normalize(v2)
        # Pad to equal length
        while len(n1) < len(n2):
            n1.append(0)
        while len(n2) < len(n1):
            n2.append(0)

        for a, b in zip(n1, n2):
            if a < b:
                return -1
            if a > b:
                return 1
        return 0

    def _assess_exploitability(self, vuln: Vulnerability) -> str:
        """Assess exploitability of vulnerability"""
        if vuln.cvss_score >= 9.0:
            return "High - Actively exploited or easy to exploit"
        elif vuln.cvss_score >= 7.0:
            return "Medium - Exploitable with some effort"
        elif vuln.cvss_score >= 4.0:
            return "Low - Difficult to exploit"
        else:
            return "Minimal - Theoretical risk"

    def _assess_business_impact(self, vuln: Vulnerability, dep: Dependency) -> str:
        """Assess business impact of vulnerability"""
        if dep.is_dev:
            return "Low - Development dependency only"

        if vuln.severity == Severity.CRITICAL:
            return "Critical - Potential data breach or service compromise"
        elif vuln.severity == Severity.HIGH:
            return "High - Significant security risk"
        elif vuln.severity == Severity.MEDIUM:
            return "Medium - Moderate security risk"
        else:
            return "Low - Minor security impact"

    def _generate_results(self) -> Dict:
        """Generate comprehensive assessment results"""
        # Count by severity
        severity_counts = {s.name: 0 for s in Severity}
        for finding in self.findings:
            severity_counts[finding.vulnerability.severity.name] += 1

        # Calculate risk score
        risk_score = self._calculate_risk_score()

        # Group findings by package
        by_package: Dict[str, List[VulnerabilityFinding]] = {}
        for finding in self.findings:
            pkg = finding.dependency.name
            if pkg not in by_package:
                by_package[pkg] = []
            by_package[pkg].append(finding)

        results = {
            'status': 'completed',
            'timestamp': datetime.now().isoformat(),
            'target': str(self.target_path),
            'scan_stats': {
                'manifest_files': self.manifest_files_found,
                'total_dependencies': len(self.dependencies),
                'vulnerable_dependencies': len(by_package),
                'total_vulnerabilities': len(self.findings)
            },
            'summary': {
                'risk_score': risk_score,
                'critical': severity_counts['CRITICAL'],
                'high': severity_counts['HIGH'],
                'medium': severity_counts['MEDIUM'],
                'low': severity_counts['LOW'],
                'total_findings': len(self.findings)
            },
            'vulnerabilities': [self._finding_to_dict(f) for f in self.findings],
            'by_ecosystem': self._group_by_ecosystem(),
            'recommendations': self._generate_recommendations()
        }

        return results

    def _calculate_risk_score(self) -> int:
        """Calculate overall risk score (0-100, lower is better)"""
        if not self.findings:
            return 0

        # Weight by severity
        total_weight = 0
        for finding in self.findings:
            severity = finding.vulnerability.severity
            if severity == Severity.CRITICAL:
                total_weight += 25
            elif severity == Severity.HIGH:
                total_weight += 10
            elif severity == Severity.MEDIUM:
                total_weight += 3
            else:
                total_weight += 1

        # Normalize to 0-100
        return min(100, total_weight)

    def _finding_to_dict(self, finding: VulnerabilityFinding) -> Dict:
        """Convert finding to dictionary"""
        return {
            'cve_id': finding.vulnerability.cve_id,
            'package': finding.dependency.name,
            'current_version': finding.dependency.version,
            'fixed_version': finding.vulnerability.fixed_version,
            'severity': finding.vulnerability.severity.name,
            'cvss_score': finding.vulnerability.cvss_score,
            'ecosystem': finding.dependency.ecosystem,
            'is_dev_dependency': finding.dependency.is_dev,
            'file_path': finding.file_path,
            'description': finding.vulnerability.description,
            'exploitability': finding.exploitability,
            'business_impact': finding.business_impact,
            'recommendation': finding.vulnerability.recommendation,
            'references': finding.vulnerability.references
        }

    def _group_by_ecosystem(self) -> Dict[str, int]:
        """Group vulnerabilities by ecosystem"""
        by_ecosystem: Dict[str, int] = {}
        for finding in self.findings:
            eco = finding.dependency.ecosystem
            by_ecosystem[eco] = by_ecosystem.get(eco, 0) + 1
        return by_ecosystem

    def _generate_recommendations(self) -> List[str]:
        """Generate prioritized recommendations"""
        recommendations = []

        critical = [f for f in self.findings if f.vulnerability.severity == Severity.CRITICAL]
        high = [f for f in self.findings if f.vulnerability.severity == Severity.HIGH]

        if critical:
            recommendations.append(
                f"CRITICAL: {len(critical)} critical vulnerabilities require immediate patching. "
                "These could lead to data breaches or system compromise."
            )
            for finding in critical[:3]:
                recommendations.append(
                    f"  - Upgrade {finding.dependency.name} to {finding.vulnerability.fixed_version or 'latest'}"
                )

        if high:
            recommendations.append(
                f"HIGH: {len(high)} high-severity vulnerabilities should be addressed soon."
            )

        if not critical and not high:
            if self.findings:
                recommendations.append(
                    "No critical or high vulnerabilities found. Address medium/low issues in regular maintenance."
                )
            else:
                recommendations.append(
                    "No known vulnerabilities found in scanned dependencies. Continue regular scanning."
                )

        return recommendations


class OutputFormatter:
    """Format assessment results for output"""

    @staticmethod
    def format_text(results: Dict, verbose: bool = False) -> str:
        """Format results as human-readable text"""
        output = []
        output.append("=" * 80)
        output.append("VULNERABILITY ASSESSMENT REPORT")
        output.append("=" * 80)
        output.append(f"Timestamp: {results['timestamp']}")
        output.append(f"Target: {results['target']}")
        output.append(f"Manifest Files Found: {results['scan_stats']['manifest_files']}")
        output.append(f"Total Dependencies: {results['scan_stats']['total_dependencies']}")
        output.append("")

        summary = results['summary']
        output.append("SUMMARY")
        output.append("-" * 80)
        output.append(f"Risk Score: {summary['risk_score']}/100 (lower is better)")
        output.append(f"Total Vulnerabilities: {summary['total_findings']}")
        output.append(f"  Critical: {summary['critical']}")
        output.append(f"  High: {summary['high']}")
        output.append(f"  Medium: {summary['medium']}")
        output.append(f"  Low: {summary['low']}")
        output.append("")

        if results['by_ecosystem']:
            output.append("BY ECOSYSTEM")
            output.append("-" * 80)
            for eco, count in results['by_ecosystem'].items():
                output.append(f"  {eco}: {count}")
            output.append("")

        if results['vulnerabilities']:
            output.append("VULNERABILITIES")
            output.append("-" * 80)
            for vuln in results['vulnerabilities'][:30]:
                output.append(f"[{vuln['severity']}] {vuln['cve_id']}: {vuln['package']} {vuln['current_version']}")
                output.append(f"  Fixed in: {vuln['fixed_version'] or 'Unknown'}")
                output.append(f"  CVSS: {vuln['cvss_score']}")
                output.append(f"  Description: {vuln['description']}")
                output.append(f"  Recommendation: {vuln['recommendation']}")
                output.append("")

        output.append("RECOMMENDATIONS")
        output.append("-" * 80)
        for i, rec in enumerate(results['recommendations'], 1):
            output.append(f"{i}. {rec}")

        output.append("=" * 80)
        return "\n".join(output)

    @staticmethod
    def format_json(results: Dict) -> str:
        """Format results as JSON"""
        return json.dumps(results, indent=2)

    @staticmethod
    def format_csv(results: Dict) -> str:
        """Format results as CSV"""
        output = StringIO()
        writer = csv.writer(output)
        writer.writerow(['cve_id', 'package', 'current_version', 'fixed_version',
                        'severity', 'cvss_score', 'ecosystem', 'recommendation'])
        for vuln in results['vulnerabilities']:
            writer.writerow([
                vuln['cve_id'], vuln['package'], vuln['current_version'],
                vuln['fixed_version'], vuln['severity'], vuln['cvss_score'],
                vuln['ecosystem'], vuln['recommendation']
            ])
        return output.getvalue()


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(
        description='Vulnerability Assessor - Dependency Vulnerability Analysis Tool',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Assess a project directory
  %(prog)s --input /path/to/project

  # Generate JSON report
  %(prog)s --input /path/to/project --output json --file vulns.json

  # Verbose output with progress
  %(prog)s --input /path/to/project --verbose

Supported Package Managers:
  - npm (package.json, package-lock.json)
  - pip (requirements.txt, Pipfile.lock, pyproject.toml)
  - Go (go.mod)
  - Cargo (Cargo.toml)
  - Maven (pom.xml)
  - RubyGems (Gemfile.lock)
        """
    )

    parser.add_argument('--input', '-i', required=True, help='File or directory to assess')
    parser.add_argument('--output', '-o', choices=['text', 'json', 'csv'], default='text',
                       help='Output format (default: text)')
    parser.add_argument('--config', '-c', help='Configuration file path (JSON)')
    parser.add_argument('--file', '-f', help='Write output to file')
    parser.add_argument('--verbose', '-v', action='store_true', help='Verbose output')

    args = parser.parse_args()

    # Validate input
    if not os.path.exists(args.input):
        print(f"Error: Input path does not exist: {args.input}", file=sys.stderr)
        sys.exit(1)

    # Load config if provided
    config = {}
    if args.config and os.path.exists(args.config):
        with open(args.config, 'r') as f:
            config = json.load(f)

    try:
        # Run assessment
        assessor = VulnerabilityAssessor(
            target_path=args.input,
            config=config,
            verbose=args.verbose
        )
        results = assessor.run()

        # Format output
        formatter = OutputFormatter()
        if args.output == 'json':
            output_text = formatter.format_json(results)
        elif args.output == 'csv':
            output_text = formatter.format_csv(results)
        else:
            output_text = formatter.format_text(results, verbose=args.verbose)

        # Write output
        if args.file:
            with open(args.file, 'w') as f:
                f.write(output_text)
            if args.verbose:
                print(f"\nReport saved to: {args.file}")
        else:
            print(output_text)

        # Exit code based on findings
        if results['summary']['critical'] > 0:
            sys.exit(2)
        elif results['summary']['high'] > 0:
            sys.exit(1)
        else:
            sys.exit(0)

    except KeyboardInterrupt:
        print("\nAssessment interrupted", file=sys.stderr)
        sys.exit(130)
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
