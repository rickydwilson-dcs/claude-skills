#!/usr/bin/env python3
"""
Output Migration Utility - One-time migration of legacy outputs

This script migrates existing outputs from the flat directory structure
to the new session-based organization system.

Usage:
    migrate_outputs.py --dry-run   # Preview migration
    migrate_outputs.py --execute   # Perform migration

Options:
    --user USER              Override git user for migration session
    --default-ticket TICKET  Default ticket for outputs without context
    --default-project NAME   Default project name for migration session
"""

import argparse
import os
import re
import shutil
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple

try:
    import yaml
except ImportError:
    # Use simple YAML implementation from session_manager
    class SimpleYAML:
        @staticmethod
        def dump(data, stream):
            """Simple YAML serializer."""
            stream.write("# Generated by migrate_outputs.py\n")
            SimpleYAML._dump_dict(data, stream, indent=0)

        @staticmethod
        def _dump_dict(data, stream, indent):
            """Recursively dump dictionary."""
            prefix = "  " * indent
            for key, value in data.items():
                if value is None:
                    stream.write(f"{prefix}{key}: null\n")
                elif isinstance(value, bool):
                    stream.write(f"{prefix}{key}: {'true' if value else 'false'}\n")
                elif isinstance(value, (int, float)):
                    stream.write(f"{prefix}{key}: {value}\n")
                elif isinstance(value, str):
                    if '\n' in value:
                        stream.write(f"{prefix}{key}: |\n")
                        for line in value.split('\n'):
                            stream.write(f"{prefix}  {line}\n")
                    elif value == "":
                        stream.write(f'{prefix}{key}: ""\n')
                    else:
                        stream.write(f'{prefix}{key}: "{value}"\n')
                elif isinstance(value, list):
                    if not value:
                        stream.write(f"{prefix}{key}: []\n")
                    else:
                        stream.write(f"{prefix}{key}:\n")
                        for item in value:
                            if isinstance(item, dict):
                                stream.write(f"{prefix}- ")
                                first = True
                                for k, v in item.items():
                                    if not first:
                                        stream.write(f"{prefix}  ")
                                    stream.write(f'{k}: "{v}"\n')
                                    first = False
                            else:
                                stream.write(f'{prefix}- "{item}"\n')
                elif isinstance(value, dict):
                    stream.write(f"{prefix}{key}:\n")
                    SimpleYAML._dump_dict(value, stream, indent + 1)

    yaml = SimpleYAML()


# ============================================================================
# CONFIGURATION
# ============================================================================

REPO_ROOT = Path(__file__).parent.parent.absolute()
OUTPUT_DIR = REPO_ROOT / "output"
SESSIONS_DIR = OUTPUT_DIR / "sessions"
ARCHIVE_DIR = OUTPUT_DIR / "archive" / "legacy-outputs"

LEGACY_CATEGORIES = ["architecture", "analysis", "reviews", "reports"]


# ============================================================================
# UTILITIES
# ============================================================================

def sanitize_username(name: str) -> str:
    """Sanitize username for directory."""
    sanitized = name.lower()
    sanitized = re.sub(r'[\s_]+', '-', sanitized)
    sanitized = re.sub(r'[^a-z0-9-]', '', sanitized)
    sanitized = re.sub(r'-+', '-', sanitized)
    sanitized = sanitized.strip('-')
    return sanitized or 'unknown-user'


def parse_filename(filename: str) -> Dict[str, str]:
    """
    Parse output filename to extract metadata.

    Expected format: YYYY-MM-DD_HH-MM-SS_topic_agent.md
    or: YYYY-MM-DD_topic_agent.md
    or: topic_agent.md
    """
    basename = Path(filename).stem

    # Pattern 1: YYYY-MM-DD_HH-MM-SS_topic_agent
    match = re.match(r'(\d{4}-\d{2}-\d{2})_(\d{2}-\d{2}-\d{2})_(.+)_(cs-.+)', basename)
    if match:
        date, time, topic, agent = match.groups()
        return {
            "date": date,
            "time": time,
            "timestamp": f"{date}_{time}",
            "topic": topic,
            "agent": agent
        }

    # Pattern 2: YYYY-MM-DD_topic_agent
    match = re.match(r'(\d{4}-\d{2}-\d{2})_(.+)_(cs-.+)', basename)
    if match:
        date, topic, agent = match.groups()
        return {
            "date": date,
            "time": "00-00-00",
            "timestamp": f"{date}_00-00-00",
            "topic": topic,
            "agent": agent
        }

    # Pattern 3: topic_agent
    match = re.match(r'(.+)_(cs-.+)', basename)
    if match:
        topic, agent = match.groups()
        return {
            "date": "2025-11-22",
            "time": "00-00-00",
            "timestamp": "2025-11-22_00-00-00",
            "topic": topic,
            "agent": agent
        }

    # Fallback: no agent pattern detected
    return {
        "date": "2025-11-22",
        "time": "00-00-00",
        "timestamp": "2025-11-22_00-00-00",
        "topic": basename,
        "agent": "unknown"
    }


def scan_legacy_outputs() -> Dict[str, List[Path]]:
    """Scan for existing outputs in legacy structure."""
    outputs = {}

    for category in LEGACY_CATEGORIES:
        category_dir = OUTPUT_DIR / category
        if not category_dir.exists():
            continue

        files = []
        for file in category_dir.iterdir():
            if file.is_file() and file.suffix == '.md':
                files.append(file)

        if files:
            outputs[category] = sorted(files)

    return outputs


def create_migration_session(
    user: str,
    email: str,
    default_ticket: str,
    default_project: str
) -> Tuple[Path, Dict]:
    """Create migration session directory and metadata."""
    session_id = "2025-11-22_migration-legacy-outputs_000000"
    user_dir = SESSIONS_DIR / user
    session_dir = user_dir / session_id

    # Create session directories
    session_dir.mkdir(parents=True, exist_ok=True)
    for category in LEGACY_CATEGORIES:
        (session_dir / category).mkdir(exist_ok=True)
    (session_dir / "artifacts").mkdir(exist_ok=True)

    # Create metadata
    now = datetime.utcnow()
    expires_at = now + timedelta(days=30)
    metadata = {
        "session_id": session_id,
        "created_at": now.strftime("%Y-%m-%dT%H:%M:%SZ"),
        "created_by": {
            "user": user,
            "email": email,
            "team": "unknown"
        },
        "context": {
            "branch": "migration",
            "ticket": default_ticket,
            "project": default_project,
            "sprint": "",
            "epic": "",
            "release": ""
        },
        "status": {
            "current": "closed",
            "closed_at": now.strftime("%Y-%m-%dT%H:%M:%SZ"),
            "archived_at": None
        },
        "outputs": [],
        "stakeholders": [],
        "retention": {
            "policy": "temporary",
            "expires_at": expires_at.strftime("%Y-%m-%d"),
            "reason": "Legacy outputs migration - review and update metadata as needed"
        },
        "links": {
            "jira": "",
            "confluence": "",
            "onedrive": "",
            "github_pr": ""
        },
        "tags": ["migration", "legacy-outputs"],
        "notes": """This session contains outputs migrated from the legacy flat directory structure.

Each output has been moved from output/{category}/ to this session directory.
File timestamps and names have been preserved.

Next Steps:
1. Review outputs and determine which are still relevant
2. Update ticket/project fields if known
3. Promote important outputs to Confluence
4. Archive or delete after 30 days if no longer needed
"""
    }

    return session_dir, metadata


def migrate_file(
    source: Path,
    dest_dir: Path,
    category: str,
    metadata: Dict
) -> bool:
    """Migrate a single file and update metadata."""
    try:
        # Copy file to new location
        dest = dest_dir / category / source.name
        shutil.copy2(source, dest)  # copy2 preserves metadata

        # Parse filename for metadata
        parsed = parse_filename(source.name)

        # Add to outputs list
        output_entry = {
            "file": f"{category}/{source.name}",
            "agent": parsed["agent"],
            "type": category,
            "created_at": f"{parsed['date']}T00:00:00Z",
            "promoted": False,
            "promoted_to": None
        }
        metadata["outputs"].append(output_entry)

        return True
    except Exception as e:
        print(f"Error migrating {source}: {e}", file=sys.stderr)
        return False


def create_backup() -> Optional[Path]:
    """Create backup of output directory."""
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    backup_dir = OUTPUT_DIR.parent / f"output.backup-{timestamp}"

    try:
        # Copy entire output directory
        shutil.copytree(OUTPUT_DIR, backup_dir, symlinks=True)
        return backup_dir
    except Exception as e:
        print(f"Failed to create backup: {e}", file=sys.stderr)
        return None


# ============================================================================
# MIGRATION LOGIC
# ============================================================================

def perform_migration(
    user: Optional[str],
    default_ticket: str,
    default_project: str,
    dry_run: bool
) -> int:
    """Perform the migration."""

    print("=" * 70)
    print("LEGACY OUTPUT MIGRATION")
    print("=" * 70)
    print()

    # Get git user info
    if not user:
        try:
            import subprocess
            result = subprocess.run(
                ["git", "config", "user.name"],
                cwd=REPO_ROOT,
                capture_output=True,
                text=True,
                check=True
            )
            git_user = result.stdout.strip()

            result = subprocess.run(
                ["git", "config", "user.email"],
                cwd=REPO_ROOT,
                capture_output=True,
                text=True,
                check=True
            )
            git_email = result.stdout.strip()
        except:
            git_user = "unknown"
            git_email = "unknown@example.com"
    else:
        git_user = user
        git_email = "unknown@example.com"

    user_sanitized = sanitize_username(git_user)

    # Scan legacy outputs
    print("üîç Scanning for legacy outputs...")
    legacy_outputs = scan_legacy_outputs()

    if not legacy_outputs:
        print("   No legacy outputs found.")
        return 0

    total_files = sum(len(files) for files in legacy_outputs.values())
    print(f"   Found {total_files} file(s) in {len(legacy_outputs)} categor{'y' if len(legacy_outputs) == 1 else 'ies'}")
    print()

    # Display what will be migrated
    for category, files in legacy_outputs.items():
        print(f"   {category}/ ({len(files)} file{'s' if len(files) != 1 else ''})")
        for file in files:
            print(f"     ‚úì {file.name}")
    print()

    # Create migration session info
    print("üìä Migration Plan:")
    print()
    print(f"   User: {user_sanitized}")
    print(f"   Session: 2025-11-22_migration-legacy-outputs_000000")
    print(f"   Ticket: {default_ticket}")
    print(f"   Project: {default_project}")
    print()

    session_path = SESSIONS_DIR / user_sanitized / "2025-11-22_migration-legacy-outputs_000000"
    print(f"   New Structure:")
    print(f"   {session_path}/")
    print(f"   ‚îú‚îÄ‚îÄ .session-metadata.yaml")
    for category in legacy_outputs.keys():
        count = len(legacy_outputs[category])
        print(f"   ‚îú‚îÄ‚îÄ {category}/ ({count} file{'s' if count != 1 else ''})")
    print()

    if dry_run:
        print("‚ö†Ô∏è  DRY RUN MODE - No changes will be made")
        print()
        print("üîÅ Run with --execute to perform migration")
        print("üíæ A backup will be created before migration")
        return 0

    # Confirm execution
    print("‚ö†Ô∏è  EXECUTING MIGRATION")
    print()
    print("This will:")
    print("  1. Create a backup of the output directory")
    print("  2. Create a new migration session")
    print("  3. Copy all legacy outputs to the session")
    print("  4. Keep original files in place (no deletion)")
    print()
    response = input("Continue? (yes/no): ").strip().lower()
    if response not in ['yes', 'y']:
        print("Migration cancelled.")
        return 1
    print()

    # Create backup
    print("üíæ Creating backup...")
    backup_path = create_backup()
    if backup_path:
        print(f"   ‚úÖ Backup created: {backup_path}")
    else:
        print("   ‚ö†Ô∏è  Backup failed - continue anyway? (yes/no): ", end="")
        response = input().strip().lower()
        if response not in ['yes', 'y']:
            print("Migration cancelled.")
            return 1
    print()

    # Create migration session
    print("üìÅ Creating migration session...")
    session_dir, metadata = create_migration_session(
        user=user_sanitized,
        email=git_email,
        default_ticket=default_ticket,
        default_project=default_project
    )
    print(f"   ‚úÖ Session created: {session_dir}")
    print()

    # Migrate files
    print("üì¶ Migrating files...")
    success_count = 0
    fail_count = 0

    for category, files in legacy_outputs.items():
        for file in files:
            if migrate_file(file, session_dir, category, metadata):
                print(f"   ‚úÖ {category}/{file.name}")
                success_count += 1
            else:
                print(f"   ‚ùå {category}/{file.name}")
                fail_count += 1
    print()

    # Write metadata
    print("üìù Writing metadata...")
    metadata_path = session_dir / ".session-metadata.yaml"
    try:
        with open(metadata_path, 'w') as f:
            yaml.dump(metadata, f)
        print(f"   ‚úÖ Metadata written: {metadata_path}")
    except Exception as e:
        print(f"   ‚ùå Failed to write metadata: {e}")
        return 1
    print()

    # Summary
    print("=" * 70)
    print("MIGRATION COMPLETE")
    print("=" * 70)
    print()
    print(f"‚úÖ Successfully migrated: {success_count} file(s)")
    if fail_count > 0:
        print(f"‚ùå Failed to migrate: {fail_count} file(s)")
    print()
    print(f"üìÅ Session location: {session_dir}")
    print(f"üìù Metadata: {metadata_path}")
    if backup_path:
        print(f"üíæ Backup: {backup_path}")
    print()
    print("Next Steps:")
    print("  1. Review migrated outputs and update metadata if needed")
    print("  2. Promote important outputs to Confluence")
    print("  3. Commit the new session to git")
    print("  4. Consider archiving or deleting legacy outputs after verification")
    print()

    return 0


# ============================================================================
# CLI INTERFACE
# ============================================================================

def main():
    """Main CLI interface."""
    parser = argparse.ArgumentParser(
        description="Migrate legacy outputs to session-based structure",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Preview migration
  %(prog)s --dry-run

  # Execute migration
  %(prog)s --execute

  # Override user
  %(prog)s --execute --user rickydwilson-dcs
"""
    )

    parser.add_argument("--dry-run", action="store_true",
                       help="Preview migration without making changes")
    parser.add_argument("--execute", action="store_true",
                       help="Execute migration")
    parser.add_argument("--user", help="Override git user for migration session")
    parser.add_argument("--default-ticket", default="MIGRATION-001",
                       help="Default ticket for migration session (default: MIGRATION-001)")
    parser.add_argument("--default-project", default="Legacy Outputs Migration",
                       help="Default project name (default: Legacy Outputs Migration)")

    args = parser.parse_args()

    if not args.dry_run and not args.execute:
        parser.print_help()
        print("\nError: Must specify either --dry-run or --execute")
        return 1

    return perform_migration(
        user=args.user,
        default_ticket=args.default_ticket,
        default_project=args.default_project,
        dry_run=args.dry_run
    )


if __name__ == "__main__":
    sys.exit(main())
